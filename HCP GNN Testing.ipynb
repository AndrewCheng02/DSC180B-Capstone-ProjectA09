{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imports\n",
    "# #Dataprep\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from nilearn import datasets, plotting, image\n",
    "# from nilearn.maskers import NiftiMapsMasker\n",
    "# from sklearn.decomposition import FastICA\n",
    "# import pandas as pd\n",
    "# import tarfile\n",
    "# import gzip\n",
    "# #sim required\n",
    "# import random\n",
    "# import pingouin as pg\n",
    "# import seaborn as sns\n",
    "# #GNN required\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.nn import Linear\n",
    "# import torch.nn as nn\n",
    "# import torch_geometric\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.nn import SAGEConv\n",
    "# from torch_geometric.nn import GraphConv\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# from torch.utils.data import SubsetRandomSampler\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1. Input Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables:**  \n",
    "**Goal**: Create different sub-graphs two decrease training times and aid in overall interpretability of GNN performance\n",
    "\n",
    "**Sub-graph Types**\n",
    "1. Significant Regions [alpha] \n",
    "2. Significant Regions [bonferroni-corrected] \n",
    "3. Graph Sampling [GRAPHSaint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jense\\AppData\\Local\\Temp\\ipykernel_8820\\2238771519.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# imports for this section\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## I. Read in the HCP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>netmat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100206</th>\n",
       "      <td>M</td>\n",
       "      <td>26-30</td>\n",
       "      <td>[[0.0, 0.61676, 9.5727, -5.4959, 0.34639, 3.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100307</th>\n",
       "      <td>F</td>\n",
       "      <td>26-30</td>\n",
       "      <td>[[0.0, -0.29664, 17.317, -9.0467, -0.28723, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100408</th>\n",
       "      <td>M</td>\n",
       "      <td>31-35</td>\n",
       "      <td>[[0.0, 1.6486, 6.6189, -8.8877, 1.4337, 1.006,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100610</th>\n",
       "      <td>M</td>\n",
       "      <td>26-30</td>\n",
       "      <td>[[0.0, -0.90275, 7.7215, -8.3907, 3.3144, 2.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101006</th>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>[[0.0, -0.088768, 9.4979, -10.412, 1.0646, 4.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender    Age                                             netmat\n",
       "subject_id                                                                 \n",
       "100206          M  26-30  [[0.0, 0.61676, 9.5727, -5.4959, 0.34639, 3.00...\n",
       "100307          F  26-30  [[0.0, -0.29664, 17.317, -9.0467, -0.28723, 1....\n",
       "100408          M  31-35  [[0.0, 1.6486, 6.6189, -8.8877, 1.4337, 1.006,...\n",
       "100610          M  26-30  [[0.0, -0.90275, 7.7215, -8.3907, 3.3144, 2.93...\n",
       "101006          F  31-35  [[0.0, -0.088768, 9.4979, -10.412, 1.0646, 4.3..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'Data/data_clean.csv.gz'\n",
    "\n",
    "with gzip.open(data_file) as filepath:\n",
    "    data = pd.read_csv(filepath, index_col = 'subject_id', \n",
    "            converters = {'netmat' : lambda x : np.array(literal_eval(re.sub('(?<!\\[)\\s+|[\\\\n]', ', ', x)))})\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Get the input subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: INPUT DATA TYPES\n",
    "# -> FILTERING\n",
    "# 1. Sig Regions [alpha] \n",
    "# 2. Sig Regions [bonferroni-corrected] \n",
    "# 3. Graph Sampling [GRAPHSaint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 276 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# full dataset\n",
    "graphs = np.stack(data.netmat.to_numpy()) # all 1003 correlation matrices\n",
    "edges = np.argwhere(graphs)\n",
    "# significant edges\n",
    "edges_sig = np.triu(np.genfromtxt('significant_edges.csv', delimiter=',')) # only keep unique edges\n",
    "graphs_sig = np.where(edges_sig, graphs, 0) # only keep significant correlations\n",
    "# bonferroni significant edges\n",
    "edges_sig_b = np.triu(np.genfromtxt('bonferroni_sig_edges.csv', delimiter=',')) # only keep unique edges\n",
    "graphs_sig_b = np.where(edges_sig, graphs, 0)# only keep significant correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edges into correct format for later\n",
    "edges_sig = torch.tensor(np.argwhere(edges_sig).T)\n",
    "edges_sig_b = torch.tensor(np.argwhere(edges_sig_b).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jense\\AppData\\Local\\Temp\\ipykernel_8820\\1997748793.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Gender'] = data['Gender'].replace({\"M\":0, \"F\":1})\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "data['Gender'] = data['Gender'].replace({\"M\":0, \"F\":1})\n",
    "labels = torch.tensor(data['Gender'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Train-Validate-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this section\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data_list):\n",
    "    \"\"\"\n",
    "    Unpacks graphs and their corresponding labels from a list of tuples.\n",
    "\n",
    "    Parameters:\n",
    "    - data_list (list of tuples): A list where each tuple contains a graph and its corresponding label.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with the following keys:\n",
    "    - 'graph' (list): A list containing all the graphs extracted from the tuples.\n",
    "    - 'label' (list): A list containing all the labels extracted from the tuples.\n",
    "    \"\"\"\n",
    "    graphs, labels = map(list, zip(*data_list))\n",
    "    return {\n",
    "        'graph': graphs,\n",
    "        'label': labels\n",
    "    }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, netmats, edges, labels, split_ratio=(0.8, 0.1, 0.1)):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with pairwise correlation matrices, labels, and edges.\n",
    "    \n",
    "        Parameters:\n",
    "        - netmats (array-like): Pairwise correlation matrices.\n",
    "        - edges (array-like): Regions that make up each pairwise correlation from `netmats`.\n",
    "        - labels (array-like): Labels indicating gender (0 for male, 1 for female).\n",
    "        - split_ratio (tuple): Ratios for splitting the data into train, validation, and test sets. Default is (0.8, 0.1, 0.1).\n",
    "    \n",
    "        Splits the data into training, validation, and test sets based on the specified split ratios.\n",
    "        \"\"\"\n",
    "        self.netmats = netmats # pairwise correlation matrix\n",
    "        self.labels = labels # female (1) or male (0)\n",
    "        self.edges = edges # regions that make up each pairwise correlation from `netmats`\n",
    "        self.split_ratios = split_ratio\n",
    "        tot = len(self.netmats)\n",
    "        train_samples = int(split_ratio[0] * tot) # 0.8\n",
    "        val_samples = int(split_ratio[1] * tot) # 0.1\n",
    "\n",
    "        # splitting the data\n",
    "        self.train_indices = np.arange(0, train_samples) # training data\n",
    "        self.val_indices = np.arange(train_samples, train_samples + val_samples) # validation data\n",
    "        self.test_indices = np.arange(train_samples + val_samples, tot) # test data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of entire dataset (train + validate + test)\n",
    "        \"\"\"\n",
    "        return len(self.netmats)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data and label corresponding to the given index.\n",
    "    \n",
    "        Parameters:\n",
    "        - idx (int): Index of the data sample to retrieve.\n",
    "    \n",
    "        Returns:\n",
    "        - graph_data (torch_geometric.data.Data): Graph data containing the correlation matrix and edge indices.\n",
    "        - label (int): Label indicating the gender (0 for male, 1 for female) of the corresponding data sample.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(self.netmats[idx]).float() # correlation matrix\n",
    "        edge_index = self.edges # dependent on input subgraph\n",
    "        graph_data = Data(x=x, edge_index=edge_index) \n",
    "        label = self.labels[idx]\n",
    "        return graph_data, label\n",
    "\n",
    "    def get_split(self, idx):\n",
    "        \"\"\"\n",
    "        Determines the split of a data sample based on its index.\n",
    "    \n",
    "        Parameters:\n",
    "        - idx (int): Index of the data sample.\n",
    "    \n",
    "        Returns:\n",
    "        - split (str): The split of the data sample ('train', 'val', or 'test').\n",
    "    \n",
    "        Raises:\n",
    "        - ValueError: If the index is not found in any of the splits.\n",
    "        \"\"\"\n",
    "        if idx in self.train_indices:\n",
    "            return 'train'\n",
    "        elif idx in self.val_indices:\n",
    "            return 'val'\n",
    "        elif idx in self.test_indices:\n",
    "            return 'test'\n",
    "        else:\n",
    "            raise ValueError('Index not in any split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(netmats, edges, labels=labels, collate_fn=collate):\n",
    "    \"\"\"\n",
    "    Creates a dataset and corresponding data loaders for training, validation, and testing.\n",
    "\n",
    "    Parameters:\n",
    "    - netmats (array-like): Pairwise correlation matrices.\n",
    "    - edges (array-like): Regions that make up each pairwise correlation from `netmats`.\n",
    "    - labels (array-like): Labels indicating gender (0 for male, 1 for female).\n",
    "    - collate_fn (function, optional): Function to collate data samples into batches. Default is `collate`.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the following keys:\n",
    "    - 'dataset' (CorrelationDataset): The created dataset.\n",
    "    - 'train_loader' (torch.utils.data.DataLoader): DataLoader for training data.\n",
    "    - 'validate_loader' (torch.utils.data.DataLoader): DataLoader for validation data.\n",
    "    - 'test_loader' (torch.utils.data.DataLoader): DataLoader for test data.\n",
    "    \"\"\"\n",
    "    dataset = CorrelationDataset(netmats, edges, labels, split_ratio=(0.8, 0.1, 0.1))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=SubsetRandomSampler(dataset.train_indices), collate_fn=collate_fn)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=SubsetRandomSampler(dataset.val_indices), collate_fn=collate_fn)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=SubsetRandomSampler(dataset.test_indices), collate_fn=collate_fn)\n",
    "    return {\n",
    "        'dataset': dataset,\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'test_loader': test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train-validate-test splits\n",
    "# full dataset\n",
    "# full =  create_dataset(graphs, edges.T)\n",
    "# significant pairwise correlations only\n",
    "sig = create_dataset(graphs, edges_sig)\n",
    "# bonferroni significant pairwise correlations only\n",
    "# sig_b = create_dataset(graphs, np.argwhere(edges_sig_b).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': [Data(x=[100, 100], edge_index=[2, 1695])], 'label': [tensor(1)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = iter(sig['train_loader'])\n",
    "next(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new imports for this section\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, device, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_true = 0\n",
    "    num_true_guesses = 0\n",
    "    for d in data_loader:\n",
    "        m = d['graph'][0]\n",
    "        m = m.to(device)\n",
    "        label = d['label'][0]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(d).squeeze()\n",
    "        loss = loss_fn(out.float(), label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = (out.double() > 0.5).float()\n",
    "        if pred == label.double():\n",
    "            num_true += 1\n",
    "        if pred == 1:\n",
    "            num_true_guesses += 1\n",
    "    return total_loss, num_true, num_true_guesses\n",
    "\n",
    "def eval(model, loader, device):\n",
    "    model.eval()\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for d in loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(d)\n",
    "            pred = (out.double() > 0.5).float()\n",
    "        y = d['label'][0]\n",
    "        cor += (pred == y).sum()\n",
    "        tot += pred.shape[0]\n",
    "    return cor/tot\n",
    "\n",
    "def train_validate_model(model, optimizer, criterion, dataset):\n",
    "    train_data = 'train_loader'\n",
    "    val_data = 'val_loader'\n",
    "    test_data = 'test_loader'\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, num_true, num_true_guesses = train(model, dataset[train_data], device, criterion, optimizer)\n",
    "        train_results = eval(model, dataset[train_data], device)\n",
    "        val_results = eval(model, dataset[val_data], device)\n",
    "        losses.append(loss)\n",
    "        avg_loss = loss / len(sig[train_data])\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs}, '\n",
    "              f'Loss: {loss}, '\n",
    "              f'Avg Loss: {avg_loss:.3f}, '\n",
    "              f'Train: {100 * train_results:.2f}%, '\n",
    "              f'Validation: {100 * val_results:.2f}%, '\n",
    "              f'Num Correct: {num_true}, '\n",
    "              f'True Guesses: {num_true_guesses} ')\n",
    "    plt.plot(losses)\n",
    "    plt.show() \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(100, 150)\n",
      "  (bn1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): GCNConv(150, 50)\n",
      "  (bn2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (classifier): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(100, 150)\n",
    "        self.bn1 = nn.BatchNorm1d(150)\n",
    "        self.conv2 = GCNConv(150, 50)\n",
    "        self.bn2 = nn.BatchNorm1d(50)\n",
    "        self.classifier = Linear(50, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data['graph'][0]\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = nn.Dropout(p=0.75)(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = nn.Dropout(p=0.75)(x)\n",
    "        x = self.classifier(x).mean(dim=0)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Loss: 553.9281856715679, Avg Loss: 0.691, Train: 46.76%, Validation: 51.00%, Num Correct: 428, True Guesses: 626 \n",
      "Epoch: 2/50, Loss: 551.9193088114262, Avg Loss: 0.688, Train: 51.87%, Validation: 46.00%, Num Correct: 425, True Guesses: 531 \n",
      "Epoch: 3/50, Loss: 554.5436206459999, Avg Loss: 0.691, Train: 45.26%, Validation: 51.00%, Num Correct: 421, True Guesses: 735 \n",
      "Epoch: 4/50, Loss: 547.5814880430698, Avg Loss: 0.683, Train: 42.14%, Validation: 47.00%, Num Correct: 444, True Guesses: 568 \n",
      "Epoch: 5/50, Loss: 537.8227994143963, Avg Loss: 0.671, Train: 38.28%, Validation: 42.00%, Num Correct: 467, True Guesses: 651 \n",
      "Epoch: 6/50, Loss: 521.7958734929562, Avg Loss: 0.651, Train: 36.78%, Validation: 41.00%, Num Correct: 502, True Guesses: 532 \n",
      "Epoch: 7/50, Loss: 482.20167081803083, Avg Loss: 0.601, Train: 35.66%, Validation: 41.00%, Num Correct: 542, True Guesses: 484 \n",
      "Epoch: 8/50, Loss: 455.2750052176416, Avg Loss: 0.568, Train: 34.16%, Validation: 40.00%, Num Correct: 573, True Guesses: 471 \n",
      "Epoch: 9/50, Loss: 430.1060725077987, Avg Loss: 0.536, Train: 33.54%, Validation: 44.00%, Num Correct: 594, True Guesses: 454 \n",
      "Epoch: 10/50, Loss: 415.9422990810126, Avg Loss: 0.519, Train: 34.66%, Validation: 43.00%, Num Correct: 601, True Guesses: 441 \n",
      "Epoch: 11/50, Loss: 389.9565868023783, Avg Loss: 0.486, Train: 35.54%, Validation: 40.00%, Num Correct: 626, True Guesses: 448 \n",
      "Epoch: 12/50, Loss: 391.5719941747375, Avg Loss: 0.488, Train: 35.41%, Validation: 41.00%, Num Correct: 615, True Guesses: 435 \n",
      "Epoch: 13/50, Loss: 376.40180076286197, Avg Loss: 0.469, Train: 35.91%, Validation: 39.00%, Num Correct: 633, True Guesses: 449 \n",
      "Epoch: 14/50, Loss: 383.1629740782082, Avg Loss: 0.478, Train: 35.29%, Validation: 40.00%, Num Correct: 624, True Guesses: 448 \n",
      "Epoch: 15/50, Loss: 360.114590436453, Avg Loss: 0.449, Train: 33.92%, Validation: 48.00%, Num Correct: 644, True Guesses: 448 \n",
      "Epoch: 16/50, Loss: 352.0797146752011, Avg Loss: 0.439, Train: 32.54%, Validation: 43.00%, Num Correct: 634, True Guesses: 440 \n",
      "Epoch: 17/50, Loss: 353.80218442482874, Avg Loss: 0.441, Train: 36.16%, Validation: 44.00%, Num Correct: 638, True Guesses: 438 \n",
      "Epoch: 18/50, Loss: 343.9648276644293, Avg Loss: 0.429, Train: 36.41%, Validation: 37.00%, Num Correct: 642, True Guesses: 428 \n",
      "Epoch: 19/50, Loss: 331.1179185414221, Avg Loss: 0.413, Train: 32.67%, Validation: 39.00%, Num Correct: 654, True Guesses: 446 \n",
      "Epoch: 20/50, Loss: 340.1253505158238, Avg Loss: 0.424, Train: 34.16%, Validation: 41.00%, Num Correct: 645, True Guesses: 441 \n",
      "Epoch: 21/50, Loss: 347.7180650867522, Avg Loss: 0.434, Train: 40.15%, Validation: 36.00%, Num Correct: 633, True Guesses: 437 \n",
      "Epoch: 22/50, Loss: 312.09176627593115, Avg Loss: 0.389, Train: 34.54%, Validation: 39.00%, Num Correct: 665, True Guesses: 433 \n",
      "Epoch: 23/50, Loss: 336.49368140718434, Avg Loss: 0.420, Train: 33.54%, Validation: 41.00%, Num Correct: 649, True Guesses: 447 \n",
      "Epoch: 24/50, Loss: 336.23281036596745, Avg Loss: 0.419, Train: 33.67%, Validation: 40.00%, Num Correct: 650, True Guesses: 436 \n",
      "Epoch: 25/50, Loss: 316.17632034770213, Avg Loss: 0.394, Train: 33.29%, Validation: 42.00%, Num Correct: 661, True Guesses: 445 \n",
      "Epoch: 26/50, Loss: 311.56956283468753, Avg Loss: 0.388, Train: 33.04%, Validation: 35.00%, Num Correct: 658, True Guesses: 438 \n",
      "Epoch: 27/50, Loss: 302.7389518979471, Avg Loss: 0.377, Train: 32.67%, Validation: 40.00%, Num Correct: 659, True Guesses: 443 \n",
      "Epoch: 28/50, Loss: 291.4071522442391, Avg Loss: 0.363, Train: 31.42%, Validation: 40.00%, Num Correct: 672, True Guesses: 426 \n",
      "Epoch: 29/50, Loss: 307.67251446889713, Avg Loss: 0.384, Train: 32.54%, Validation: 41.00%, Num Correct: 655, True Guesses: 433 \n",
      "Epoch: 30/50, Loss: 299.11586464132415, Avg Loss: 0.373, Train: 33.42%, Validation: 36.00%, Num Correct: 664, True Guesses: 428 \n",
      "Epoch: 31/50, Loss: 292.52386008080794, Avg Loss: 0.365, Train: 34.79%, Validation: 31.00%, Num Correct: 665, True Guesses: 443 \n",
      "Epoch: 32/50, Loss: 278.8356157277012, Avg Loss: 0.348, Train: 31.92%, Validation: 40.00%, Num Correct: 678, True Guesses: 432 \n",
      "Epoch: 33/50, Loss: 301.9683777546743, Avg Loss: 0.377, Train: 35.29%, Validation: 39.00%, Num Correct: 670, True Guesses: 434 \n",
      "Epoch: 34/50, Loss: 290.48447013029363, Avg Loss: 0.362, Train: 35.16%, Validation: 41.00%, Num Correct: 675, True Guesses: 443 \n",
      "Epoch: 35/50, Loss: 302.4787364313088, Avg Loss: 0.377, Train: 33.92%, Validation: 47.00%, Num Correct: 679, True Guesses: 443 \n",
      "Epoch: 36/50, Loss: 281.9896098243771, Avg Loss: 0.352, Train: 34.79%, Validation: 35.00%, Num Correct: 683, True Guesses: 431 \n",
      "Epoch: 37/50, Loss: 270.83800837839954, Avg Loss: 0.338, Train: 35.29%, Validation: 40.00%, Num Correct: 682, True Guesses: 438 \n",
      "Epoch: 38/50, Loss: 270.08677704341244, Avg Loss: 0.337, Train: 33.04%, Validation: 41.00%, Num Correct: 685, True Guesses: 439 \n",
      "Epoch: 39/50, Loss: 276.24131983995903, Avg Loss: 0.344, Train: 34.16%, Validation: 42.00%, Num Correct: 684, True Guesses: 428 \n",
      "Epoch: 40/50, Loss: 264.1861763053457, Avg Loss: 0.329, Train: 34.91%, Validation: 40.00%, Num Correct: 687, True Guesses: 441 \n",
      "Epoch: 41/50, Loss: 274.8781819610449, Avg Loss: 0.343, Train: 33.29%, Validation: 42.00%, Num Correct: 681, True Guesses: 429 \n",
      "Epoch: 42/50, Loss: 269.76737091813993, Avg Loss: 0.336, Train: 33.04%, Validation: 38.00%, Num Correct: 685, True Guesses: 445 \n",
      "Epoch: 43/50, Loss: 258.64007576028234, Avg Loss: 0.322, Train: 33.17%, Validation: 41.00%, Num Correct: 681, True Guesses: 435 \n",
      "Epoch: 44/50, Loss: 269.7810882569174, Avg Loss: 0.336, Train: 32.67%, Validation: 39.00%, Num Correct: 685, True Guesses: 441 \n",
      "Epoch: 45/50, Loss: 279.45003923767945, Avg Loss: 0.348, Train: 38.90%, Validation: 39.00%, Num Correct: 676, True Guesses: 452 \n",
      "Epoch: 46/50, Loss: 265.4103803887847, Avg Loss: 0.331, Train: 33.29%, Validation: 41.00%, Num Correct: 679, True Guesses: 427 \n",
      "Epoch: 47/50, Loss: 253.43968061234045, Avg Loss: 0.316, Train: 33.17%, Validation: 38.00%, Num Correct: 700, True Guesses: 426 \n",
      "Epoch: 48/50, Loss: 297.17609468259616, Avg Loss: 0.371, Train: 32.79%, Validation: 46.00%, Num Correct: 668, True Guesses: 434 \n",
      "Epoch: 49/50, Loss: 253.30415814963635, Avg Loss: 0.316, Train: 32.67%, Validation: 39.00%, Num Correct: 693, True Guesses: 439 \n",
      "Epoch: 50/50, Loss: 261.5718418400793, Avg Loss: 0.326, Train: 35.66%, Validation: 38.00%, Num Correct: 689, True Guesses: 439 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3261494287282784"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validate_model(model=model, optimizer=torch.optim.Adam(model.parameters(), lr=0.003), criterion=nn.BCELoss(), dataset=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer models\n",
    "\n",
    "class twoGCN_custom(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Convolutional Network (GCN) with customizable hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimension of the input features.\n",
    "        hidden_dim1 (int): Dimension of the first hidden layer.\n",
    "        hidden_dim2 (int): Dimension of the second hidden layer.\n",
    "        output_dim (int): Dimension of the output.\n",
    "        dropout_prob (float): Dropout probability.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (GCNConv): First graph convolutional layer.\n",
    "        bn1 (BatchNorm1d): Batch normalization layer for the first hidden layer.\n",
    "        conv2 (GCNConv): Second graph convolutional layer.\n",
    "        bn2 (BatchNorm1d): Batch normalization layer for the second hidden layer.\n",
    "        classifier (Linear): Linear layer for classification.\n",
    "        dropout_prob (float): Dropout probability.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout_prob):\n",
    "        super(twoGCN_custom, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.classifier = Linear(hidden_dim2, 1) # output dimension will always be 1\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data['graph'][0]\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = nn.Dropout(p=self.dropout_prob)(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = nn.Dropout(p=self.dropout_prob)(x)\n",
    "        x = self.classifier(x).mean(dim=0)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twoGCN_custom(\n",
      "  (conv1): GCNConv(100, 150)\n",
      "  (bn1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): GCNConv(150, 50)\n",
      "  (bn2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (classifier): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "Epoch: 1/50, Loss: 554.1513394713402, Avg Loss: 0.691, Train: 51.62%, Validation: 52.00%, Num Correct: 421, True Guesses: 665 \n",
      "Epoch: 2/50, Loss: 555.713864326477, Avg Loss: 0.693, Train: 50.75%, Validation: 58.00%, Num Correct: 413, True Guesses: 677 \n",
      "Epoch: 3/50, Loss: 555.1831057071686, Avg Loss: 0.692, Train: 53.12%, Validation: 46.00%, Num Correct: 424, True Guesses: 662 \n",
      "Epoch: 4/50, Loss: 555.3193711638451, Avg Loss: 0.692, Train: 51.87%, Validation: 55.00%, Num Correct: 412, True Guesses: 678 \n",
      "Epoch: 5/50, Loss: 556.0938875079155, Avg Loss: 0.693, Train: 52.37%, Validation: 47.00%, Num Correct: 404, True Guesses: 666 \n",
      "Epoch: 6/50, Loss: 555.1137402653694, Avg Loss: 0.692, Train: 51.00%, Validation: 52.00%, Num Correct: 427, True Guesses: 667 \n",
      "Epoch: 7/50, Loss: 555.6252665519714, Avg Loss: 0.693, Train: 52.00%, Validation: 53.00%, Num Correct: 411, True Guesses: 671 \n",
      "Epoch: 8/50, Loss: 556.0921890735626, Avg Loss: 0.693, Train: 51.12%, Validation: 48.00%, Num Correct: 413, True Guesses: 653 \n",
      "Epoch: 9/50, Loss: 555.6004852056503, Avg Loss: 0.693, Train: 48.38%, Validation: 55.00%, Num Correct: 395, True Guesses: 653 \n",
      "Epoch: 10/50, Loss: 555.0355906486511, Avg Loss: 0.692, Train: 51.25%, Validation: 43.00%, Num Correct: 423, True Guesses: 655 \n",
      "Epoch: 11/50, Loss: 555.9989376068115, Avg Loss: 0.693, Train: 51.12%, Validation: 50.00%, Num Correct: 414, True Guesses: 674 \n",
      "Epoch: 12/50, Loss: 555.8799725174904, Avg Loss: 0.693, Train: 50.75%, Validation: 52.00%, Num Correct: 419, True Guesses: 667 \n",
      "Epoch: 13/50, Loss: 555.4344089627266, Avg Loss: 0.693, Train: 52.99%, Validation: 50.00%, Num Correct: 412, True Guesses: 678 \n",
      "Epoch: 14/50, Loss: 555.0618036985397, Avg Loss: 0.692, Train: 50.12%, Validation: 51.00%, Num Correct: 416, True Guesses: 668 \n",
      "Epoch: 15/50, Loss: 555.1616614460945, Avg Loss: 0.692, Train: 49.38%, Validation: 54.00%, Num Correct: 425, True Guesses: 677 \n",
      "Epoch: 16/50, Loss: 554.9738630056381, Avg Loss: 0.692, Train: 49.13%, Validation: 54.00%, Num Correct: 421, True Guesses: 671 \n",
      "Epoch: 17/50, Loss: 555.1765239834785, Avg Loss: 0.692, Train: 51.12%, Validation: 56.00%, Num Correct: 412, True Guesses: 666 \n",
      "Epoch: 18/50, Loss: 554.9264975190163, Avg Loss: 0.692, Train: 50.62%, Validation: 50.00%, Num Correct: 428, True Guesses: 652 \n",
      "Epoch: 19/50, Loss: 555.3653203845024, Avg Loss: 0.692, Train: 52.12%, Validation: 49.00%, Num Correct: 436, True Guesses: 692 \n",
      "Epoch: 20/50, Loss: 555.3612604141235, Avg Loss: 0.692, Train: 53.24%, Validation: 50.00%, Num Correct: 427, True Guesses: 671 \n",
      "Epoch: 21/50, Loss: 555.0824365019798, Avg Loss: 0.692, Train: 51.75%, Validation: 49.00%, Num Correct: 412, True Guesses: 668 \n",
      "Epoch: 22/50, Loss: 554.9952149391174, Avg Loss: 0.692, Train: 50.37%, Validation: 37.00%, Num Correct: 437, True Guesses: 663 \n",
      "Epoch: 23/50, Loss: 555.0600780844688, Avg Loss: 0.692, Train: 53.37%, Validation: 48.00%, Num Correct: 440, True Guesses: 654 \n",
      "Epoch: 24/50, Loss: 554.8560121655464, Avg Loss: 0.692, Train: 50.00%, Validation: 49.00%, Num Correct: 421, True Guesses: 653 \n",
      "Epoch: 25/50, Loss: 555.4055652022362, Avg Loss: 0.693, Train: 51.12%, Validation: 52.00%, Num Correct: 410, True Guesses: 664 \n",
      "Epoch: 26/50, Loss: 554.7769042253494, Avg Loss: 0.692, Train: 52.37%, Validation: 59.00%, Num Correct: 423, True Guesses: 677 \n",
      "Epoch: 27/50, Loss: 555.8906936645508, Avg Loss: 0.693, Train: 50.87%, Validation: 51.00%, Num Correct: 414, True Guesses: 664 \n",
      "Epoch: 28/50, Loss: 555.9485040307045, Avg Loss: 0.693, Train: 50.25%, Validation: 46.00%, Num Correct: 411, True Guesses: 681 \n",
      "Epoch: 29/50, Loss: 555.3877238035202, Avg Loss: 0.693, Train: 50.50%, Validation: 55.00%, Num Correct: 415, True Guesses: 673 \n",
      "Epoch: 30/50, Loss: 554.6860311031342, Avg Loss: 0.692, Train: 54.11%, Validation: 48.00%, Num Correct: 431, True Guesses: 669 \n",
      "Epoch: 31/50, Loss: 555.7991720438004, Avg Loss: 0.693, Train: 52.74%, Validation: 49.00%, Num Correct: 417, True Guesses: 671 \n",
      "Epoch: 32/50, Loss: 555.686871945858, Avg Loss: 0.693, Train: 50.00%, Validation: 47.00%, Num Correct: 407, True Guesses: 665 \n",
      "Epoch: 33/50, Loss: 556.5433408021927, Avg Loss: 0.694, Train: 50.25%, Validation: 49.00%, Num Correct: 393, True Guesses: 663 \n",
      "Epoch: 34/50, Loss: 555.20362585783, Avg Loss: 0.692, Train: 51.62%, Validation: 56.00%, Num Correct: 414, True Guesses: 688 \n",
      "Epoch: 35/50, Loss: 555.6302596330643, Avg Loss: 0.693, Train: 52.24%, Validation: 52.00%, Num Correct: 413, True Guesses: 667 \n",
      "Epoch: 36/50, Loss: 554.7955407500267, Avg Loss: 0.692, Train: 52.24%, Validation: 55.00%, Num Correct: 426, True Guesses: 670 \n",
      "Epoch: 37/50, Loss: 555.4029088020325, Avg Loss: 0.693, Train: 51.87%, Validation: 47.00%, Num Correct: 417, True Guesses: 679 \n",
      "Epoch: 38/50, Loss: 555.3961895704269, Avg Loss: 0.693, Train: 52.74%, Validation: 52.00%, Num Correct: 423, True Guesses: 661 \n",
      "Epoch: 39/50, Loss: 555.9594368338585, Avg Loss: 0.693, Train: 52.24%, Validation: 53.00%, Num Correct: 402, True Guesses: 676 \n",
      "Epoch: 40/50, Loss: 555.0842547416687, Avg Loss: 0.692, Train: 53.62%, Validation: 55.00%, Num Correct: 443, True Guesses: 677 \n",
      "Epoch: 41/50, Loss: 556.2096046805382, Avg Loss: 0.694, Train: 51.12%, Validation: 55.00%, Num Correct: 401, True Guesses: 675 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m twoGCN_1 \u001b[38;5;241m=\u001b[39m twoGCN_custom(\n\u001b[0;32m      2\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      3\u001b[0m     hidden_dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     activation_functions\u001b[38;5;241m=\u001b[39m[torch\u001b[38;5;241m.\u001b[39mtanh, torch\u001b[38;5;241m.\u001b[39mtanh]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(twoGCN_1)\n\u001b[1;32m----> 9\u001b[0m train_validate_model(model\u001b[38;5;241m=\u001b[39mtwoGCN_1, optimizer\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m), criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss(), dataset\u001b[38;5;241m=\u001b[39msig)\n",
      "Cell \u001b[1;32mIn[172], line 49\u001b[0m, in \u001b[0;36mtrain_validate_model\u001b[1;34m(model, optimizer, criterion, dataset)\u001b[0m\n\u001b[0;32m     47\u001b[0m loss, num_true, num_true_guesses \u001b[38;5;241m=\u001b[39m train(model, dataset[train_data], device, criterion, optimizer)\n\u001b[0;32m     48\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, dataset[train_data], device)\n\u001b[1;32m---> 49\u001b[0m val_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, dataset[val_data], device)\n\u001b[0;32m     50\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     51\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(sig[train_data])\n",
      "Cell \u001b[1;32mIn[172], line 29\u001b[0m, in \u001b[0;36meval\u001b[1;34m(model, loader, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 29\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(d)\n\u001b[0;32m     30\u001b[0m         pred \u001b[38;5;241m=\u001b[39m (out\u001b[38;5;241m.\u001b[39mdouble() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     31\u001b[0m     y \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[194], line 38\u001b[0m, in \u001b[0;36mtwoGCN_custom.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     36\u001b[0m data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     37\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:244\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    241\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight,\n\u001b[0;32m    245\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[0;32m    453\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[1;32m--> 455\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_args, edge_index, size,\n\u001b[0;32m    456\u001b[0m                           kwargs)\n\u001b[0;32m    458\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[1;32m--> 329\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lift(data, edge_index, dim)\n\u001b[0;32m    331\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "twoGCN_1 = twoGCN_custom(\n",
    "    input_dim=100,\n",
    "    hidden_dim1=150, \n",
    "    hidden_dim2=50, \n",
    "    dropout_prob=0.50,\n",
    "    activation_functions=[torch.tanh, torch.tanh]\n",
    ")\n",
    "print(twoGCN_1)\n",
    "train_validate_model(model=twoGCN_1, optimizer=torch.optim.Adam(model.parameters(), lr=0.003), criterion=nn.BCELoss(), dataset=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twoGCN_1 = twoGCN_custom(\n",
    "#     input_dim=100,\n",
    "#     hidden_dim1=150, \n",
    "#     hidden_dim2=50, \n",
    "#     dropout_prob=0.50,\n",
    "#     activation_functions=[torch.tanh, torch.tanh]\n",
    "# )\n",
    "# print(twoGCN_1)\n",
    "# train_validate_model(model=twoGCN_1, optimizer=torch.optim.Adam(model.parameters(), lr=0.003), criterion=nn.BCELoss(), dataset=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twoGCN_3 = twoGCN_custom(\n",
    "#     input_dim=100, \n",
    "#     hidden_dim1=150, \n",
    "#     hidden_dim2=50, \n",
    "#     dropout_prob=0.50,\n",
    "#     activation_functions=[tanh, tanh]\n",
    "# )\n",
    "# print(twoGCN_2)\n",
    "# train_validate_model(model=twoGCN_3, optimizer=torch.optim.Adam(model.parameters(), lr=0.003), criterion=nn.BCELoss(), dataset=sig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
